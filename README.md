THIS FILE IS MACHINE GENERATED. IT IS NOT GAURANTEED TO BE CORRECT, ONLY LIKELY TO BE.

# small_personal_projects
## Description
This directory contains a collection of small personal projects, including a web application for rolling powers from a Celestial Forge document, a real-time whisper transcription system, scripts for training GPT models, and a simple README generator. The projects utilize various libraries and technologies such as Gradio, PyTorch, and OpenAI API for text generation.

# small_personal_projects\celestial_forge_roller_webui
## Description
This directory contains a web application for rolling powers from a Celestial Forge document. The application is built using the Gradio library and allows users to select domains, choose roll settings, and save roll history. It also includes a list of 38 unique abilities and items that can be acquired in the Celestial Forge system.

# Easy [Real Time Whisper Transcription](https://github.com/davabase/whisper_real_time)

This repository is meant to make using the Real Time Whisper Transcription repo easier by providing a simple installation method for all of its requirements as well as CUDA accelerated PyTorch. 

It also includes some minor script improvements:
- Implements [`faster-whisper`](https://github.com/SYSTRAN/faster-whisper) to reduce transcription delay further
- Minor adjustment to script logic to make the transcription better
- Transcription log saving

### Conda Torch environments are quite large. 
The virtual environment and Whisper model together is over 10GB!

To install the dependencies, install Anaconda and create an isolated Conda environment with 
```
conda env create -p <env path> --file <environment.yml path>
``` 
Then, activate the environment with 
```
conda activate <env path>
```

Now you should be able to execute `python transcribe_demo.py` and have real-time transcription!
>On first run, the script will download the Whisper model to the script's directory.
>Whisper 'medium' is the default; it is ~1.5GB on disk and needs ~4GB of VRAM to run.


# small_personal_projects\gpt_from_scratch
## Description
This directory contains a collection of scripts and modules for training and fine-tuning GPT models. It includes a Python module for gradient filtering, a Conda environment file for deep learning tasks, and scripts for training GPT models on the Shakespeare dataset. The scripts utilize the PyTorch library and the GrokFast library for efficient gradient accumulation.

# small_personal_projects\simple_readme_generator
## Requirements
- `pip install requests`
- An OpenAI API-compatible text generation backend at localhost:5000 (I recommend [this one](https://github.com/oobabooga/text-generation-webui) ).
- A Llama 3/3.1 model.
## Description
This directory contains a simple script to generate README.md files for directories and their subdirectories using a text generation API. The project requires the requests and tkinter libraries for functionality.

# .gitignore
## Description:
This file contains a list of files and directories to be ignored by Git. It is used to exclude certain files and directories from being tracked and committed to the repository.

## Contents:
- __pycache__: A directory containing compiled Python bytecode files, which are generated by the Python interpreter. These files are not necessary for the project and can be safely ignored.
- not_functional: A file likely containing non-functional code or test cases. This file is not relevant to the project and can be excluded from version control.